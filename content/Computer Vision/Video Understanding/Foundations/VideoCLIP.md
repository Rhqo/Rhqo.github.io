우리는 VideoCLIP을 소개합니다. VideoCLIP은 제로샷 비디오 및 텍스트 이해를 위해 통합 모델을 사전 훈련하는 대비 접근 방식으로, 다운스트림 작업에서 라벨을 사용하지 않습니다. VideoCLIP은 변환기(transformer)를 사용하여 비디오와 텍스트를 훈련시키며, 시간적으로 겹치는 긍정적인 비디오-텍스트 쌍과 최근접 이웃 검색에서의 어려운 부정 샘플을 대비합니다.

다양한 다운스트림 작업, 즉 시퀀스 수준의 텍스트-비디오 검색, 비디오 질문 응답(VideoQA), 토큰 수준의 행동 위치 지정, 행동 분할에 대한 실험 결과는 이전 작업을 초월하는 최신 성능을 보여주며, 일부 경우에는 감독 방식(supervised approach)을 초월하는 성과를 보입니다. 코드는 이 URL에서 제공됩니다.