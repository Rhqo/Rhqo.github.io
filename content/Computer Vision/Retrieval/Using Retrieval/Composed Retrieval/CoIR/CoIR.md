---
title: CoIR
draft: false
tags:
---
### Survey
```embed
title: "A Survey of Multimodal Composite Editing and Retrieval"
image: "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
description: "In the real world, where information is abundant and diverse across different modalities, understanding and utilizing various data types to improve retrieval systems is a key focus of research. Multimodal composite retrieval integrates diverse modalities such as text, image and audio, etc. to provide more accurate, personalized, and contextually relevant results. To facilitate a deeper understanding of this promising direction, this survey explores multimodal composite editing and retrieval in depth, covering image-text composite editing, image-text composite retrieval, and other multimodal composite retrieval. In this survey, we systematically organize the application scenarios, methods, benchmarks, experiments, and future directions. Multimodal learning is a hot topic in large model era, and have also witnessed some surveys in multimodal learning and vision-language models with transformers published in the PAMI journal. To the best of our knowledge, this survey is the first comprehensive review of the literature on multimodal composite retrieval, which is a timely complement of multimodal fusion to existing reviews. To help readersâ€™ quickly track this field, we build the project page for this survey, which can be found at https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval."
url: "https://arxiv.org/abs/2409.05405"
```

### Composed Image Retrieval
- Effective conditioned and composed image retrieval combining CLIP-based features
- [[Pic2Word]]: Mapping Pictures to Words for Zero-shot Composed Image Retrieval
- [[InstructPix2Pix]]: Learning to Follow Image Editing Instructions
- Image Retrieval on Real-life Images with Pre-trained Vision-and-Language Models
- [[MagicLens]]: Self-Supervised Image Retrieval with Open-Ended Instructions