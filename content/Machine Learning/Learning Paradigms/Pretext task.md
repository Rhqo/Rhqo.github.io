모델이 유용한 표현(특징)을 학습하기 위해 수행하는 초기 학습 과제

주로 self-supervised learning에서 사용되며, 레이블이 없는 데이터로부터 의미 있는 표현을 학습하기 위해 설계된다. 
전처리 과제는 본래의 목적과는 다른, 하지만 표현 학습에 도움이 되는 간단한 작업을 의미한다.    
본 논문에서는 텍스트-이미지 쌍의 contrastive learning을 pretext task로 사용한다.